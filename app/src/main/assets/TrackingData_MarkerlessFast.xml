<?xml version="1.0"?>

<TrackingData>
	<Sensors>
		<Sensor Type="FeatureBasedSensorSource" Subtype="Fast">

			<!--	Assign an ID to this sensor -->
			<SensorID>FeatureTracking1</SensorID>

			<Parameters>
			
				<FeatureDescriptorAlignment>regular</FeatureDescriptorAlignment>
				
				<MaxObjectsToDetectPerFrame>5</MaxObjectsToDetectPerFrame>
				
			
				<MaxObjectsToTrackInParallel>1</MaxObjectsToTrackInParallel>

				<SimilarityThreshold>0.7</SimilarityThreshold>
					
			</Parameters>


			<SensorCOS>
				<SensorCosID>Patch1</SensorCosID>
				<Parameters>
					<ReferenceImage>DS1.png</ReferenceImage>
					<SimilarityThreshold>0.7</SimilarityThreshold>
				</Parameters>
			</SensorCOS>
           
			<!--	The commented lines below show how another COS can be 
					added to the configuration. -->
			<!--
			<SensorCOS>
				<SensorCosID>Patch2</SensorCosID>
				<Parameters>
					<ReferenceImage>junaioman.png</ReferenceImage>
					<SimilarityThreshold>0.8</SimilarityThreshold>
				</Parameters>
			</SensorCOS>
			-->

		</Sensor>
	</Sensors>
	<Connections>
		<COS>

			<!--	A descriptive name for this COS. -->
			<Name>MarkerlessCOS1</Name>

			<!--	Which type of Fuser to use. Here, we use the 
					"SmoothingFuser", which applies smoothing in order to predict 
					movement and handle noise. 
					-->
			<Fuser Type="SmoothingFuser">
				<Parameters>
					
					<!--	Number of frames in which the tracker will continue 
							predicting the pose when interframe tracking 
							fails. After the specified number of frames, the 
							tracker will stop predicting. 
							This parameter is for expert usage only. In general 
							it is advised to leave the value unchanged. -->
					<KeepPoseForNumberOfFrames>2</KeepPoseForNumberOfFrames>
					
					<!--	If the tracking device is equipped with an inertial 
							sensor that can measure gravity, the sensor's 
							measurement is used to improve the pose 
							estimate. To activate this option, the value of 
							this tag must be set to "ReplaceZAxis". 
							This parameter is for expert usage only. In general 
							it is advised to leave the value unchanged. -->
					<GravityAssistance></GravityAssistance>
					
					<!--	Data (position) smoothing factor for double 
							exponential smoothing of translation. This value 
							should be high if measures are expected to be 
							accurate and low otherwise. A high value assigns a 
							higher weight to a new measurement. Typically, the 
							accuracy of translation estimates is rather 
							high, so we set the smoothing factor to 0.8. The 
							default value is 0.5. 
							This parameter is for expert usage only. In general 
							it is advised to leave the value unchanged. -->
					<AlphaTranslation>1.0</AlphaTranslation>
					
					<!--	Trend (velocity) smoothing factor for double 
							exponential smoothing of translation. This value 
							should be high if measures are expected to be 
							accurate and low otherwise. With the same 
							reasoning as above, we set the smoothing factor to 
							0.8. The default value is 0.5. 
							This parameter is for expert usage only. In general 
							it is advised to leave the value unchanged. -->
					<GammaTranslation>1.0</GammaTranslation>

					<!--	Data (position) smoothing factor for double 
							exponential smoothing of rotation. Rotation 
							measurements are typically not as accurate as 
							translation measurements, so we use a value of 0.5.
							This parameter is for expert usage only. In general 
							it is advised to leave the value unchanged. -->
					<AlphaRotation>0.8</AlphaRotation>
	
					<!--	Trend (velocity) smoothing factor for double 
							exponential smoothing of rotation. With the same
							reasoning as for AlphaRotation above, we set this 
							value to 0.5. 
							This parameter is for expert usage only. In general 
							it is advised to leave the value unchanged. -->
					<GammaRotation>0.8</GammaRotation>
					
					<!--	If an orientation sensor is available, the system
							may try to keep updating the pose based on that 
							orientation sensor's measurements. If this should
							be done, then this option must be set to true. The 
							default value is false. 
							This parameter is for expert usage only. In general 
							it is advised to leave the value unchanged. -->
					<ContinueLostTrackingWithOrientationSensor>false</ContinueLostTrackingWithOrientationSensor>
				</Parameters>
			</Fuser>

			<SensorSource>

				<!--	The Sensor and SensorCOS that we want to use. Note 
						that these IDs are the same that we have used in the 
						Sensor definition above. -->
				<SensorID>FeatureTracking1</SensorID>
				<SensorCosID>Patch1</SensorCosID>

				<!--	A hand-eye calibration allows to specify the relative 
						pose between two sensors. In the simple case of having 
						one camera-based sensor, it is usually not used. It 
						allows to move the COS "as if" the camera were moved, 
						and is thus inverse to the COSOffset rigid 
						transformation that is specified below. -->
				<HandEyeCalibration>
				
					<!--	The 3D translation vector. -->
					<TranslationOffset>
						<X>0</X>
						<Y>0</Y>
						<Z>0</Z>
					</TranslationOffset>
					
					<!--	Rotations are specified via unit quaternions, where 
							the imaginary parts "X", "Y", "Z" is specified 
							first, and then the real part "W". --> 
					<RotationOffset>
						<X>0</X>
						<Y>0</Y>
						<Z>0</Z>
						<W>1</W>
					</RotationOffset>
				</HandEyeCalibration>

				<!--	The COSOffset specifies a rigid transformation that 
						is applied to the SensorCOS. This makes it possible to
						move the augmented model. It is specified just the same 
						way as the hand-eye-calibration. -->
				<COSOffset>
					<TranslationOffset>
						<X>0</X>
						<Y>0</Y>
						<Z>0</Z>
					</TranslationOffset>
					<RotationOffset>
						<X>0</X>
						<Y>0</Y>
						<Z>0</Z>
						<W>1</W>
					</RotationOffset>
				</COSOffset>
			</SensorSource>
		</COS>
    </Connections>
</TrackingData>
